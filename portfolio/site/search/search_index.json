{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"My Portfolio A show case of all Yi-Chun Chang's work Introduction This is the a mkdocs website to demo projects You can find all of the projects listed below in a importance-order Check more about me in my home page Index FROZEN - Freeze your impulse to buy NSFW Detection - Not Safe For Work content detection API The Tank Series - The Ultimate Tank Gen2 - Arduino-based Gen1 - FPGA-based Modeling user willingness of data contribution in online social networks - Help to collect your data from social network faster Gender Differences on StackOverflow - So... What's the population sketch of the world's largest SEs' community? The Haunted Village - Escape from the ghosts with you besties on PC! deepeye_pack - An automatic data visualization system Back to Home Page","title":"Home"},{"location":"#my-portfolio","text":"","title":"My Portfolio"},{"location":"#a-show-case-of-all-yi-chun-changs-work","text":"","title":"A show case of all Yi-Chun Chang's work"},{"location":"#introduction","text":"This is the a mkdocs website to demo projects You can find all of the projects listed below in a importance-order Check more about me in my home page","title":"Introduction"},{"location":"#index","text":"FROZEN - Freeze your impulse to buy NSFW Detection - Not Safe For Work content detection API The Tank Series - The Ultimate Tank Gen2 - Arduino-based Gen1 - FPGA-based Modeling user willingness of data contribution in online social networks - Help to collect your data from social network faster Gender Differences on StackOverflow - So... What's the population sketch of the world's largest SEs' community? The Haunted Village - Escape from the ghosts with you besties on PC! deepeye_pack - An automatic data visualization system Back to Home Page","title":"Index"},{"location":"deepeye_pack/deepeye_pack/","text":"deepeye_pack An automatic data visualization Python package Introduction This is a Python package to wrapped up the DeepEye API using Python 2.7 The DeepEye system is an automatic data visualization system which can easily visualize data without too much effort. It is designed to provide with really simple usage. The DeepEye system Github page: https://github.com/TsinghuaDatabaseGroup/DeepEye/tree/master/APIs_Deepeye The original paper: DeepEye: An automatic big data visualization framework Problem Research Q1: Understand the foundation of DeepEye system Q2: Analyze the design of DeepEye APIs Q3: Design a set of process to wrap up the APIs Analyze Process The traditional process of data visualization can be visualized as following - Load Dataset - Select Attributes \u2190\u2190\u2190\u2190\u2190\u2190 - Data Transformation \u2191 LOOP - Check Visualization \u2192\u2192\u2192\u2192\u2192\u2192 This process is too complex because one set of data can be visualized into many different patterns. e.g. Line Chart Bar Chart Pie Chart And the combinatin of all attributes can cause it too laborious and time-consuming to find the perfect choice for the resulting visualization. Hence, the DeepEye system is to solve the above problems The DeepEye system can be described as the following parts: 1. Visualization Recognition - Whether the chart is good or bad 2. Visualization Ranking - Which are better charts 3. Visualization Selection - Select the top-k most suitable charts 6. The architecture of DeepEye system can be illustrated as following: Implementation Process Overview Understand DeepEye System workflow Design wrapper workflow based on the above Implement initialization process of wrapper Implement multiple data import methods Integrate the DeepEye algorithms into wrapper Implement multiple output methods Testing the process on multiple platforms Understand DeepEye System workflow As described in the Analyze Process Design wrapper workflow based on the above Deepeye-pack should be user-friendly and easy to use Based on the 'Query' idea of DB - User can 'query' charts by a set of commands The process is concluded as: 1. Set up the attributes and types of a table 2. Import the data from file or DB 3. Choose different methods to generate the visualizations(Learning to rank, Partial order, Diversified ranking) 4. Output the result in multiple way(html, jsons...) Implement initialization process of wrapper Set up the table info for DeepEye User should specify the attributes needed and the types of them accordingly Define a class to handle all the methods Implement multiple data import methods Since the data can be imported from different sources, I need to make sure the data imported from different methods are the same The requirements from the lab is to imported from MySQL and csv file. For the MySQL method, import relative packages and wrap the package into one command to query all data. Pick attributes needed according to initialization For the csv file method, simply import and filter attributes not required. Integrate the DeepEye algorithms into wrapper Import DeepEye to make sure the algorithms work for the current package. Prune the non-required code and make sure it won't hurt the dependency Implement multiple output methods When generate multiple charts, the management of the result data is messy Clean and file the output data in multiple fashion. Hence, the user can choose on their need Testing the process on multiple platforms Wrap into package and tested under different OS My role in the project This is a project made during my time @Datalab in Tsinghua University in Beijing I was assigned this task by the leading professor of the lab Guoliang Li During the development, I was under the instruction of an excellent doctoral student - Yuyu Luo Huge thanks to Professor Li and my friend Yuyu Luo Conclusion As this is my first time working alone on one project, I was not familiar with the environment and the working methods. I was encouraged to learn most of the knowledge through Internet because the algorithms used are pretty much mature for a long time. After a basic understanding of the concept of the system, I worked around on their demo websites many times to get a proper idea of how to design my wrapper can be a more popular fashion. Besides building the wrapper, I also looked into the implementation of the DeepEye algorithms. Though the fact that I was not capable of building the system on myself, I get in the first contact with deep learning and ranking algorithms which enrich my knowledge a lot.","title":"deepeye_pack"},{"location":"deepeye_pack/deepeye_pack/#deepeye_pack","text":"","title":"deepeye_pack"},{"location":"deepeye_pack/deepeye_pack/#an-automatic-data-visualization-python-package","text":"","title":"An automatic data visualization Python package"},{"location":"deepeye_pack/deepeye_pack/#introduction","text":"This is a Python package to wrapped up the DeepEye API using Python 2.7 The DeepEye system is an automatic data visualization system which can easily visualize data without too much effort. It is designed to provide with really simple usage. The DeepEye system Github page: https://github.com/TsinghuaDatabaseGroup/DeepEye/tree/master/APIs_Deepeye The original paper: DeepEye: An automatic big data visualization framework","title":"Introduction"},{"location":"deepeye_pack/deepeye_pack/#problem-research","text":"Q1: Understand the foundation of DeepEye system Q2: Analyze the design of DeepEye APIs Q3: Design a set of process to wrap up the APIs","title":"Problem Research"},{"location":"deepeye_pack/deepeye_pack/#analyze-process","text":"The traditional process of data visualization can be visualized as following - Load Dataset - Select Attributes \u2190\u2190\u2190\u2190\u2190\u2190 - Data Transformation \u2191 LOOP - Check Visualization \u2192\u2192\u2192\u2192\u2192\u2192 This process is too complex because one set of data can be visualized into many different patterns. e.g. Line Chart Bar Chart Pie Chart And the combinatin of all attributes can cause it too laborious and time-consuming to find the perfect choice for the resulting visualization. Hence, the DeepEye system is to solve the above problems The DeepEye system can be described as the following parts: 1. Visualization Recognition - Whether the chart is good or bad 2. Visualization Ranking - Which are better charts 3. Visualization Selection - Select the top-k most suitable charts 6. The architecture of DeepEye system can be illustrated as following:","title":"Analyze Process"},{"location":"deepeye_pack/deepeye_pack/#implementation-process","text":"","title":"Implementation Process"},{"location":"deepeye_pack/deepeye_pack/#overview","text":"Understand DeepEye System workflow Design wrapper workflow based on the above Implement initialization process of wrapper Implement multiple data import methods Integrate the DeepEye algorithms into wrapper Implement multiple output methods Testing the process on multiple platforms","title":"Overview"},{"location":"deepeye_pack/deepeye_pack/#understand-deepeye-system-workflow","text":"As described in the Analyze Process","title":"Understand DeepEye System workflow"},{"location":"deepeye_pack/deepeye_pack/#design-wrapper-workflow-based-on-the-above","text":"Deepeye-pack should be user-friendly and easy to use Based on the 'Query' idea of DB - User can 'query' charts by a set of commands The process is concluded as: 1. Set up the attributes and types of a table 2. Import the data from file or DB 3. Choose different methods to generate the visualizations(Learning to rank, Partial order, Diversified ranking) 4. Output the result in multiple way(html, jsons...)","title":"Design wrapper workflow based on the above"},{"location":"deepeye_pack/deepeye_pack/#implement-initialization-process-of-wrapper","text":"Set up the table info for DeepEye User should specify the attributes needed and the types of them accordingly Define a class to handle all the methods","title":"Implement initialization process of wrapper"},{"location":"deepeye_pack/deepeye_pack/#implement-multiple-data-import-methods","text":"Since the data can be imported from different sources, I need to make sure the data imported from different methods are the same The requirements from the lab is to imported from MySQL and csv file. For the MySQL method, import relative packages and wrap the package into one command to query all data. Pick attributes needed according to initialization For the csv file method, simply import and filter attributes not required.","title":"Implement multiple data import methods"},{"location":"deepeye_pack/deepeye_pack/#integrate-the-deepeye-algorithms-into-wrapper","text":"Import DeepEye to make sure the algorithms work for the current package. Prune the non-required code and make sure it won't hurt the dependency","title":"Integrate the DeepEye algorithms into wrapper"},{"location":"deepeye_pack/deepeye_pack/#implement-multiple-output-methods","text":"When generate multiple charts, the management of the result data is messy Clean and file the output data in multiple fashion. Hence, the user can choose on their need","title":"Implement multiple output methods"},{"location":"deepeye_pack/deepeye_pack/#testing-the-process-on-multiple-platforms","text":"Wrap into package and tested under different OS","title":"Testing the process on multiple platforms"},{"location":"deepeye_pack/deepeye_pack/#my-role-in-the-project","text":"This is a project made during my time @Datalab in Tsinghua University in Beijing I was assigned this task by the leading professor of the lab Guoliang Li During the development, I was under the instruction of an excellent doctoral student - Yuyu Luo Huge thanks to Professor Li and my friend Yuyu Luo","title":"My role in the project"},{"location":"deepeye_pack/deepeye_pack/#conclusion","text":"As this is my first time working alone on one project, I was not familiar with the environment and the working methods. I was encouraged to learn most of the knowledge through Internet because the algorithms used are pretty much mature for a long time. After a basic understanding of the concept of the system, I worked around on their demo websites many times to get a proper idea of how to design my wrapper can be a more popular fashion. Besides building the wrapper, I also looked into the implementation of the DeepEye algorithms. Though the fact that I was not capable of building the system on myself, I get in the first contact with deep learning and ranking algorithms which enrich my knowledge a lot.","title":"Conclusion"},{"location":"frozen/frozen/","text":"FROZEN Freeze your impulse to buy Introduction FROZEN is an app to prevent impulsive consumption It aims to use a simulation game to prevent user from buying stuff they dont actually need When you first enter the app, you need to change your password or your payment method If you choose to use OTP(One-Time Pin) as payment password, we would implement a mechanism to \"Freeze\" your access to the OTP. If you choose change password, we would told you a secret key which you need to add to your own password. Together they form the whole password, and we would \"Freeze\" it before you buy anything. We would ask you a few questions about what you are about to buy according to the necessity and emergence of the product. And we would also ask you to stop for a while according to your previous consumption method If you successfully gave up the idea of buying, then you will be rewarded in the game However, if you insisted to buy, you would be punished in the game Apart from that, we would record every time of your consumption intention and evaluate of your user sketch Your game performance is based on the action of your every consumption The Game The game's theme is regarding polar bears on ice bergs Your actions represent virtual carbon footprint By buying more stuff, more virtual carbon footprint is created. Hence, the ice berg would shrink, threatening your polar bears By buying less, less virtual carbon footprint is created, the ice berg will grow and attract more polar bears on to the ice berg When your ice reach certain value, an amount of donation would be sent to the foundation polarbearsinternational.org Presentation My Role in the Team First task My main responsibility is to coordinate the communication between front-end and back-end Both teams were working on their own side and forgot the other one completely When we tried to combine, there were too many issues to handle I had to design a DB for the communication to go through Second Task Another of my responsibility was to develop the prompt system for the game. The system is highly related to the user behavior If the prompt was too frequent it will cause the user to become annoyed and causing the customer stickiness of the app to drop We discuss several times to decide when is the best time for the prompt to come out and as in what kind of styles","title":"FROZEN"},{"location":"frozen/frozen/#frozen","text":"","title":"FROZEN"},{"location":"frozen/frozen/#freeze-your-impulse-to-buy","text":"","title":"Freeze your impulse to buy"},{"location":"frozen/frozen/#introduction","text":"FROZEN is an app to prevent impulsive consumption It aims to use a simulation game to prevent user from buying stuff they dont actually need When you first enter the app, you need to change your password or your payment method If you choose to use OTP(One-Time Pin) as payment password, we would implement a mechanism to \"Freeze\" your access to the OTP. If you choose change password, we would told you a secret key which you need to add to your own password. Together they form the whole password, and we would \"Freeze\" it before you buy anything. We would ask you a few questions about what you are about to buy according to the necessity and emergence of the product. And we would also ask you to stop for a while according to your previous consumption method If you successfully gave up the idea of buying, then you will be rewarded in the game However, if you insisted to buy, you would be punished in the game Apart from that, we would record every time of your consumption intention and evaluate of your user sketch Your game performance is based on the action of your every consumption","title":"Introduction"},{"location":"frozen/frozen/#the-game","text":"The game's theme is regarding polar bears on ice bergs Your actions represent virtual carbon footprint By buying more stuff, more virtual carbon footprint is created. Hence, the ice berg would shrink, threatening your polar bears By buying less, less virtual carbon footprint is created, the ice berg will grow and attract more polar bears on to the ice berg When your ice reach certain value, an amount of donation would be sent to the foundation polarbearsinternational.org","title":"The Game"},{"location":"frozen/frozen/#presentation","text":"","title":"Presentation"},{"location":"frozen/frozen/#my-role-in-the-team","text":"","title":"My Role in the Team"},{"location":"frozen/frozen/#first-task","text":"My main responsibility is to coordinate the communication between front-end and back-end Both teams were working on their own side and forgot the other one completely When we tried to combine, there were too many issues to handle I had to design a DB for the communication to go through","title":"First task"},{"location":"frozen/frozen/#second-task","text":"Another of my responsibility was to develop the prompt system for the game. The system is highly related to the user behavior If the prompt was too frequent it will cause the user to become annoyed and causing the customer stickiness of the app to drop We discuss several times to decide when is the best time for the prompt to come out and as in what kind of styles","title":"Second Task"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/","text":"Gender Differences on StackOverflow So... What's the population sketch of the world's largest SEs' community? Abstract With the rise of programming as an essential job in every market, people have been eager to learn and evolve, and thus some platforms were developed to share the knowledge between programmers. Stack Overflow was our choice for the study of gender differences on this kind of platform, due to the criticism it received for being toxic, sexist and sometimes racist. The purpose of the study is to understand the gender differences on Stack Overflow in terms of participation, and in order to figure that out we used several APIs for data collection and analysis, for example Microsoft Azure sentiment analysis tool to analyze the results of each gender. We later found out that: Men and women ask approximately the same number of questions while men roughly answer twice as much. Women have a more spread sentiment polarity than men, even though the average score for both was almost neutral. We then conclude that even though our results might not have shown lots of differences between men and women, they paved the way for future studies to ask why instead of what and look for the reasons behind these results we got. Introduction Through our research, we have strived to bring to light the gender differences in participation of users on the professional question and answer site, Stack Overflow. The platform is focused around a wide range of computer programming topics and has received criticism in the past for its toxic culture and unwelcoming environment. Stack Overflow has become so heavily utilised because its incentives such as reputation points and badge awards make it an efficient way to exchange and share knowledge. The community on the site places a high level of importance on these arbitrary achievements because many people use their Stack Overflow account to add to their resume to show that they are knowledgeable in their field. Many people use this platform very seriously and we believe that the real life value of Stack Overflow makes it an effective medium to analyse the divide between the participation of Men and Women in the programming community. Our goals The key objective of our research is to investigate if and how men and women participate differently on Stack Overflow in order to better understand the gender differences in the programming community. Research into the causes of differences is necessary, which is why we would like to better understand the dynamics of participation in order to improve the value of crowdsourced knowledge. Our research has focused heavily on answers because the quality of responses is crucial for the success of Stack Overflows incentivizing systems. We want to understand if there are differences in answers between users of differering reputation scores and to recognize if there are differences between men and women in how they formulate their answers to questions. Our results will be used as a starting point for further investigation of the underlying reasons that account for these conclusions. Research Questions In our research, we focused specifically on the following research questions: 1. Does the number of questions and answers posted differ between men and women? 2. Do men and women express their answers differently? How does the sentiment differ in their answers? 3. How does the sentiment of the answers with regard to the user\u2019s reputation scores and rewards differ between men and women? Keeping our research questions in mind, we had hypothesised that Men would have a higher number of answers and that the sentimental analysis would prove that there are stark differences in the way that Men and Women express their answers. Implementation Process Overview Data collection is a process which plays a vital role of the project. In order to collect the data for further investigation, we need a lot of APIs and tools to help us gather or analyze the data we need. For this project, we decided to use Python 3 as the main programming language because of the interactive and data-prone attribute of itself. However, we took the Jupyter notebook as \u2018playground\u2019 to construct the framework. After the test run, we converted the code into a script with classes and ran them in the command line. As of the size of the data, we took it step by step listed below. Each team member first gather the requir data for each step and combine them together for the next step. Collect the user data with Stackoverflow API (in short SO API ) with attributes we need. Convert location infos through Bing / Google Maps APIs and infer the gender of the users with a Python package called Gender Guesser Clean and filter the data according to the gender. Crawl answers of each user and analyzed the sentiment of the answers with Microsoft Azure sentiment analysis service . Data Retrieval by StackOverflow API(SO API) Stackoverflow provides a series of different APIs which enable us to access the data conveniently. However, the rules of how to access the data is quite strict. Without an application key, each IP can only have up to 300 queries/day.The amount is too few which doesn\u2019t match our requirement. Luckily, they provide an \u2018application method\u2019 which enables each application with 10,000 queries/day. Each user needs to apply for the application on Stackoverflow and the API would be usable only through OAuth 2.0. Besides, the API has a time restriction that would require some backoff for crawling. After the problems with the restriction were dealt with, we discussed which attributes we need for the users. The attributes include information, the number of questions and answers and additional ones listed in the below: - user_id - display_name - gender - location - badge_counts - reputation - accept_rate - question_count - answer_count - up_vote_count - down_vote_count - account_id - user_type With the information, we then transfer the code to script and batch the crawler with some technique that allows us to crawl up to 1,000,000 users/day with each application. Nonetheless, we decided to use only a small portion of the allowance because some of the queries should be used on the following parts. Gender Guesser with Bing/Google Maps API Next, we tried to infer gender from the data we have. First of all, we discussed the tool we need for the inferring and chose the gender_guesser python tool. Gender inferring requires both the real first name of the user and the country of the user. Nevertheless, the name and location of raw user data didn\u2019t meet the input requirements. Therefore, we decided to retrieve the first name and convert the location to country with Bing/Google Maps APIs to fit with the input. The result came out quite nice and we would look into them in the Analysis part. Data Preprocessing Now with the user data with gender, we need to decide our sample base. We first combine the data from each team member and remove the duplicated and non-user data by checking whether the user is registered or not. Then, the uncertain gender(mostly male/female, unknown) were removed from the data. And to verify our result by gender guesser, we sample 50 male and females from the results to verify them manually on the Stack Overflow site. Furthermore, we kept the balance between male and female dataset by shuffling and sampling the male data to the number of female data. Sentimental Analysis With each user and their gender, we now be able to look at the last two parts of our research questions regarding the sentiments of the answers of each user. The process is done by using the Microsoft Azure Text Analytics tool. The tool is very powerful and easy to use. We can just pass the text and it would return a score between 0 and 1. The sentiment is more positive if the score is higher. For each user, we crawl max 50 answers for analysis. But when we checked the answers from the SO API, we found out the answers themselves contain quite a lot of other information regarding code blocks and markups. These sections are cleaned up first before we send them to the Azure API. With each user having their score with different length, we stored the data to json to better accessibility. Results In this section we discuss our findings and provide insights into the participation of genders based on the research questions. Research Question 1: How does the number of questions and answers posted differ between men and women? The first question we ask is whether we can see a difference in the activity levels of men and women on the site. Our key variable is the number of questions asked and the number of answers posted, and we see that there are significant differences between men and women. The Fig.1 shows the average activity levels across genders. In our methodology, we used mean values to calculate the average number of questions and answers. It is an important element of our data that we need to analyze since it represents the engagement on the site per gender. The average number of questions asked is 23 for men and 27 for women, while the average number of answers posted is 150 for men and 78 for women. In other words, men answer 48% more questions on average than women do, while women ask 15% more. There are several possible explanations for this finding, however, it is not exactly clear why this is the case. For instance that the patterns of behavior on the site have changed, or because of our approach to gender inference (i.e. we used gender-guesser) or data selection (i.e. we collected the data sorted by the most reputable genders). Therefore, men are more active on the site across these metrics. Furthermore, we also found that women are more likely to ask questions and are less engaged in the Q&A discussions. Research Question 2: Do men and women express their answers differently? How does the sentiment differ in their answers? As mentioned in the previous section we found differences in both activity and outcome between men and women. In this research question, we ask whether there are any differences in how men and women express their answers? Specifically, how does their sentiment differ? We plot polarity score distribution box plots for both genders in below 2 Figs. We found that women tend to have more spread sentiment polarity distribution, as opposed to men, who tend to answer the questions in a more neutral way. It is not clear what might be the reason, as future research must be done to explore the potential reasons. In below fig, we can also observe that most of the users who are men tend to score closer to the neutral polarity. It is also the case that women score higher than men in both the positive and negative ends of the spectrum. Research Question 3: How does the sentiment of the answers with regard to the user\u2019s reputation scores and rewards differ between men and women? In this research question, we ask how the sentiment of the answers influences the probability of having higher reputation between the genders? The primary way to gain reputation is by posting good questions and useful answers. A user gains reputation when the answer is voted up, the answer is marked \u201caccepted\u201d and others. We plot the average sentiment scores per genders as well as their reputation in below 2 Figs. The users who tend to give answers in a more neutral form tend to have a higher reputation than the user who answers sound closer negative or closer to positive. In terms of gender differences, the distribution of the women\u2019s reputation is skewed up towards a more positive sentiment. Nevertheless, the correlation between high reputation and neutral answers is still visible in both genders equally. We also considered how the sentiment of an answer is correlated with the users\u2019 rewards. On StackOverflow, users get badges by participating on the site. There are a variety of different badges, but they\u2019re all categorized into gold, silver, and bronze ones. In our study, we assigned them the weight from 1 to 3 depending on the value of the badge. We have then explored the relationship between the user\u2019s average sentiment scores. The distribution of rewards for both genders are very similar regardless of their average user sentiment scores (in below 2 figs.) References Predicting the Quality of Questions on Stackoverflow Someone like me: How does peer parity influence participation of women on stack overflow? Discovering value from community activity on focused question answering sites: a case study of stack overflow Confidence in Programming Skills: Gender Insights From StackOverflow Developers Survey Google Scholar Search My role in the project I implemented most of the Python script in the entire project Especially handled the large data crawler and work out solution towards the Azure services I also resolved the API limit of Google maps and Bing maps and mapping of countries Conclusion In our research, we have provided some insights into the behaviour of men and women on the developer platform StackOverflow that women ask more questions than men, whereas men post more answers. We further achieved more insights into the way users express themselves in their answers. Huge thanks to the Lecturer of this course at UZH - Prof. Dr. Anik\u00f3 Hann\u00e1k Also great thanks to my partners in the Social Computing Lesson. Especially, Natalie Hennig and Daniel Gareev. A Great exchange experience which enhance my ability to conduct researches","title":"Gender Differences on StackOverflow"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#gender-differences-on-stackoverflow","text":"","title":"Gender Differences on StackOverflow"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#so-whats-the-population-sketch-of-the-worlds-largest-ses-community","text":"","title":"So... What's the population sketch of the world's largest SEs' community?"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#abstract","text":"With the rise of programming as an essential job in every market, people have been eager to learn and evolve, and thus some platforms were developed to share the knowledge between programmers. Stack Overflow was our choice for the study of gender differences on this kind of platform, due to the criticism it received for being toxic, sexist and sometimes racist. The purpose of the study is to understand the gender differences on Stack Overflow in terms of participation, and in order to figure that out we used several APIs for data collection and analysis, for example Microsoft Azure sentiment analysis tool to analyze the results of each gender. We later found out that: Men and women ask approximately the same number of questions while men roughly answer twice as much. Women have a more spread sentiment polarity than men, even though the average score for both was almost neutral. We then conclude that even though our results might not have shown lots of differences between men and women, they paved the way for future studies to ask why instead of what and look for the reasons behind these results we got.","title":"Abstract"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#introduction","text":"Through our research, we have strived to bring to light the gender differences in participation of users on the professional question and answer site, Stack Overflow. The platform is focused around a wide range of computer programming topics and has received criticism in the past for its toxic culture and unwelcoming environment. Stack Overflow has become so heavily utilised because its incentives such as reputation points and badge awards make it an efficient way to exchange and share knowledge. The community on the site places a high level of importance on these arbitrary achievements because many people use their Stack Overflow account to add to their resume to show that they are knowledgeable in their field. Many people use this platform very seriously and we believe that the real life value of Stack Overflow makes it an effective medium to analyse the divide between the participation of Men and Women in the programming community.","title":"Introduction"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#our-goals","text":"The key objective of our research is to investigate if and how men and women participate differently on Stack Overflow in order to better understand the gender differences in the programming community. Research into the causes of differences is necessary, which is why we would like to better understand the dynamics of participation in order to improve the value of crowdsourced knowledge. Our research has focused heavily on answers because the quality of responses is crucial for the success of Stack Overflows incentivizing systems. We want to understand if there are differences in answers between users of differering reputation scores and to recognize if there are differences between men and women in how they formulate their answers to questions. Our results will be used as a starting point for further investigation of the underlying reasons that account for these conclusions.","title":"Our goals"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#research-questions","text":"In our research, we focused specifically on the following research questions: 1. Does the number of questions and answers posted differ between men and women? 2. Do men and women express their answers differently? How does the sentiment differ in their answers? 3. How does the sentiment of the answers with regard to the user\u2019s reputation scores and rewards differ between men and women? Keeping our research questions in mind, we had hypothesised that Men would have a higher number of answers and that the sentimental analysis would prove that there are stark differences in the way that Men and Women express their answers.","title":"Research Questions"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#implementation-process","text":"","title":"Implementation Process"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#overview","text":"Data collection is a process which plays a vital role of the project. In order to collect the data for further investigation, we need a lot of APIs and tools to help us gather or analyze the data we need. For this project, we decided to use Python 3 as the main programming language because of the interactive and data-prone attribute of itself. However, we took the Jupyter notebook as \u2018playground\u2019 to construct the framework. After the test run, we converted the code into a script with classes and ran them in the command line. As of the size of the data, we took it step by step listed below. Each team member first gather the requir data for each step and combine them together for the next step. Collect the user data with Stackoverflow API (in short SO API ) with attributes we need. Convert location infos through Bing / Google Maps APIs and infer the gender of the users with a Python package called Gender Guesser Clean and filter the data according to the gender. Crawl answers of each user and analyzed the sentiment of the answers with Microsoft Azure sentiment analysis service .","title":"Overview"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#data-retrieval-by-stackoverflow-apiso-api","text":"Stackoverflow provides a series of different APIs which enable us to access the data conveniently. However, the rules of how to access the data is quite strict. Without an application key, each IP can only have up to 300 queries/day.The amount is too few which doesn\u2019t match our requirement. Luckily, they provide an \u2018application method\u2019 which enables each application with 10,000 queries/day. Each user needs to apply for the application on Stackoverflow and the API would be usable only through OAuth 2.0. Besides, the API has a time restriction that would require some backoff for crawling. After the problems with the restriction were dealt with, we discussed which attributes we need for the users. The attributes include information, the number of questions and answers and additional ones listed in the below: - user_id - display_name - gender - location - badge_counts - reputation - accept_rate - question_count - answer_count - up_vote_count - down_vote_count - account_id - user_type With the information, we then transfer the code to script and batch the crawler with some technique that allows us to crawl up to 1,000,000 users/day with each application. Nonetheless, we decided to use only a small portion of the allowance because some of the queries should be used on the following parts.","title":"Data Retrieval by StackOverflow API(SO API)"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#gender-guesser-with-binggoogle-maps-api","text":"Next, we tried to infer gender from the data we have. First of all, we discussed the tool we need for the inferring and chose the gender_guesser python tool. Gender inferring requires both the real first name of the user and the country of the user. Nevertheless, the name and location of raw user data didn\u2019t meet the input requirements. Therefore, we decided to retrieve the first name and convert the location to country with Bing/Google Maps APIs to fit with the input. The result came out quite nice and we would look into them in the Analysis part.","title":"Gender Guesser with Bing/Google Maps API"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#data-preprocessing","text":"Now with the user data with gender, we need to decide our sample base. We first combine the data from each team member and remove the duplicated and non-user data by checking whether the user is registered or not. Then, the uncertain gender(mostly male/female, unknown) were removed from the data. And to verify our result by gender guesser, we sample 50 male and females from the results to verify them manually on the Stack Overflow site. Furthermore, we kept the balance between male and female dataset by shuffling and sampling the male data to the number of female data.","title":"Data Preprocessing"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#sentimental-analysis","text":"With each user and their gender, we now be able to look at the last two parts of our research questions regarding the sentiments of the answers of each user. The process is done by using the Microsoft Azure Text Analytics tool. The tool is very powerful and easy to use. We can just pass the text and it would return a score between 0 and 1. The sentiment is more positive if the score is higher. For each user, we crawl max 50 answers for analysis. But when we checked the answers from the SO API, we found out the answers themselves contain quite a lot of other information regarding code blocks and markups. These sections are cleaned up first before we send them to the Azure API. With each user having their score with different length, we stored the data to json to better accessibility.","title":"Sentimental Analysis"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#results","text":"In this section we discuss our findings and provide insights into the participation of genders based on the research questions.","title":"Results"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#research-question-1","text":"How does the number of questions and answers posted differ between men and women? The first question we ask is whether we can see a difference in the activity levels of men and women on the site. Our key variable is the number of questions asked and the number of answers posted, and we see that there are significant differences between men and women. The Fig.1 shows the average activity levels across genders. In our methodology, we used mean values to calculate the average number of questions and answers. It is an important element of our data that we need to analyze since it represents the engagement on the site per gender. The average number of questions asked is 23 for men and 27 for women, while the average number of answers posted is 150 for men and 78 for women. In other words, men answer 48% more questions on average than women do, while women ask 15% more. There are several possible explanations for this finding, however, it is not exactly clear why this is the case. For instance that the patterns of behavior on the site have changed, or because of our approach to gender inference (i.e. we used gender-guesser) or data selection (i.e. we collected the data sorted by the most reputable genders). Therefore, men are more active on the site across these metrics. Furthermore, we also found that women are more likely to ask questions and are less engaged in the Q&A discussions.","title":"Research Question 1:"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#research-question-2","text":"Do men and women express their answers differently? How does the sentiment differ in their answers? As mentioned in the previous section we found differences in both activity and outcome between men and women. In this research question, we ask whether there are any differences in how men and women express their answers? Specifically, how does their sentiment differ? We plot polarity score distribution box plots for both genders in below 2 Figs. We found that women tend to have more spread sentiment polarity distribution, as opposed to men, who tend to answer the questions in a more neutral way. It is not clear what might be the reason, as future research must be done to explore the potential reasons. In below fig, we can also observe that most of the users who are men tend to score closer to the neutral polarity. It is also the case that women score higher than men in both the positive and negative ends of the spectrum.","title":"Research Question 2:"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#research-question-3","text":"How does the sentiment of the answers with regard to the user\u2019s reputation scores and rewards differ between men and women? In this research question, we ask how the sentiment of the answers influences the probability of having higher reputation between the genders? The primary way to gain reputation is by posting good questions and useful answers. A user gains reputation when the answer is voted up, the answer is marked \u201caccepted\u201d and others. We plot the average sentiment scores per genders as well as their reputation in below 2 Figs. The users who tend to give answers in a more neutral form tend to have a higher reputation than the user who answers sound closer negative or closer to positive. In terms of gender differences, the distribution of the women\u2019s reputation is skewed up towards a more positive sentiment. Nevertheless, the correlation between high reputation and neutral answers is still visible in both genders equally. We also considered how the sentiment of an answer is correlated with the users\u2019 rewards. On StackOverflow, users get badges by participating on the site. There are a variety of different badges, but they\u2019re all categorized into gold, silver, and bronze ones. In our study, we assigned them the weight from 1 to 3 depending on the value of the badge. We have then explored the relationship between the user\u2019s average sentiment scores. The distribution of rewards for both genders are very similar regardless of their average user sentiment scores (in below 2 figs.)","title":"Research Question 3:"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#references","text":"Predicting the Quality of Questions on Stackoverflow Someone like me: How does peer parity influence participation of women on stack overflow? Discovering value from community activity on focused question answering sites: a case study of stack overflow Confidence in Programming Skills: Gender Insights From StackOverflow Developers Survey Google Scholar Search","title":"References"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#my-role-in-the-project","text":"I implemented most of the Python script in the entire project Especially handled the large data crawler and work out solution towards the Azure services I also resolved the API limit of Google maps and Bing maps and mapping of countries","title":"My role in the project"},{"location":"gender_differences_on_stackoverflow/gender_differences_on_stackoverflow/#conclusion","text":"In our research, we have provided some insights into the behaviour of men and women on the developer platform StackOverflow that women ask more questions than men, whereas men post more answers. We further achieved more insights into the way users express themselves in their answers. Huge thanks to the Lecturer of this course at UZH - Prof. Dr. Anik\u00f3 Hann\u00e1k Also great thanks to my partners in the Social Computing Lesson. Especially, Natalie Hennig and Daniel Gareev. A Great exchange experience which enhance my ability to conduct researches","title":"Conclusion"},{"location":"modeling_user_willingness/modeling_user_willingness/","text":"Modeling user willingness of data contribution in online social networks Help to collect your data from social network faster Abstract As the social network becoming one of the most important parts in our daily life, the data we produce while interacting with the social networks became a valuable asset. Therefore, the protection over these data are escalating day by day. However, the research which requires to use the data from social networks can not be conducted smoothly. To gather the data, a lot of time was wasted. Therefore, my team and I implemented a Python Machine Learning model that helps to collect data from social network in a more efficient fashion by judging the willingness of the user group intelligently. Problem Research Under the implementation of GDPR(General Data Protection Regulation) since 2018, Social network companies like Facebook and Twitter would apply more protection to their data. However, in order to research on topics regarding social networks, data collection would become harder. Hence, we would like to acquire the public data on social network and analyze them through machine learning model based on the individual elements and situational elements. Eventually, we would like to find users who are more likely to provide their private data through our model. Analyze Process Questions What is the relationship between the user willingness and their public data? Generally there are ground truth for questions to be solved by ML models, however, is there such a ground truth in our question? The young people are more likely to receive our survey instead of the elder ones. Will this cause any bias problem? Lots of values on the public data would be missing, is it possible to solve the problem through preprocessing? How to select the model and refine it to increase accuracy and eventually reach the goal? Flowchart Flowchart of our model Current Research Comparioson Social network now plays an important role in everyone's life, therefore the protection of eyeryone's data becomes an important question. The following paragraph will focus solely on the relationship between user willingness and their behavior and data User Consent Analysis The elements which affect social group willingness are as following: Privacy Paradox Users care about their privacy when asked about, but they don't protect their privacy enough on the Internet Perceived Privacy Users' perception of privacy danger differ from the actual danger Context Users' more likely to trade their private data for services or benefits Culture Different culture treats privacy differently User Diversity Users' education background, personality and etc. affect how they react to privacy protection Gender Different gender treats privacy with different attitude We would conduct our research according to the above aspects in a data science perspective Implementation Process Data collection Collect the users' willingness through survey over Faceboook regarding: Whether they are willing to give their public account information to academic experiemnts without payment Whether they are willing to give their public account information to academic experiemnts with payment Whether they are willing to give their private account information to academic experiemnts without payment Whether they are willing to give their private account information to academic experiemnts with payment The survevry is distributed on multi different platform and channel to achieve as little bias as possible. Crawl the data according to users' willingness. Mostly their public account information such as personal data friend list liked posts number of posts We used selenium and Beautiful Soup and several bot afcebook accounts to crawl the above mentioned data The active data like posts and likes are crawled in a limited time frame Data Preprocessing The dimension of the raw data is quite high - for over 37 different attributes including educational background, working experience, birthday and etc. The raw data also has a quite high percentage of missing values. If one attribute has too high missing value, it will be removed. If low missing value, interpolation is used to fill up the missing value For Example, User ID is removed because it does not provide any meaning The raw data is then categorized using nominal feature, ordinal feature and temporal feature. If features are being too similar, we would combine the features together For nominal features, one-hot encoding is applied to remove bias. For some of the ordinal features, total and frequency over time can be calculated. As for the temporal features, most of these are binned up by a week or a month We categorized users' hometown and living place according to continentals using GeoMapping and Google Maps API. We sorted the educational backgrounds according to the QS and similar ranking standards The raw data is then divided into train data and test data using K-fold cross validation The raw data is scaled standardized and normalized as well The feature selection and extraction were then applied to the raw data. Such as Sequential Backward Selection to remove noises and LDA can select important features. Training We selected several models such as SVM, random forest, adaboost and xgboost which fits better with smaller dataset We applied SMOTE to do upsampling to balance the ratio of the positive and negative data We then use grid search to refine the parameter for the model Performance Conclusion The basic accuracy is around 72% After refining, the accuracy is now at 82% The accuracy can be further improved if more user data can be collected. Also, as described above, the users' willingness is highly related to one's personality as well, so maybe inspect the content of the posts to identify the personality would be a good break. Active Learning As our research move on to the next level, we found out that we lack of data Our research is 'small-dataset', 'low cost to achieve non-labelled data' and 'high cost to label each data'. Therefore, it is a perfect fit for Active Learning Our plan is to crawl large data on Facebook and ask the user about his or her willingness about giving the data, which can further used on training the model itself. Model of the Active Learning The action to pick up which users to ask is called query strategy The labeled data would then be feed to an AL Learner There are various query strategies the unlabelled data. Besides the default methods, we implemented our own query strategy These query strategies were combined and cross-validated through the grid-search The iteration can quickly convergent after 200 queries And the result of the different query strategies are as followed: Reference Laufer, R. S. and Wolfe, M., Privacy as a concept and a social issue: Amultidimensional developmental theory, 1977. Martina Ziefle, Julian Halbey and Sylvia Kowalewski, Users\u2019 Willingness to ShareData on the Internet: Perceived Benefits and Caveats, 2016. Jie Zhao, Chanjuan Zhu, Zhixiang Peng, Xin Xu and Yan Liu, User Willingnesstoward Knowledge Sharing in Social Networks, 2018. Catherine, M., Some antecedents and effects of trust in virtual communities, 2002. Burr Settles, Active Learning Literature Survey, 2010. My role in the project I am mainly responsible for the data preprocessing and model refining I refined the model to increase its accuracy for 20% Furthermore, I handled most of the implementation of the Active Learning's query strategies Conclusion As my Bachelor's thesis, this Project brought me great impact over ML Its the very first big scale ML project I not only learned the programming of ML but also the proper way of conducting research on ML-related issues The project also increased my interests on the social computing I started to be aware of the things that we missed when using the convenient services provided by the online/game companies these days When they tricked us in exchange with our priceless data, they didn't protect them and ever worse. Some of them even sell them for benefits. I am proud that I have conducted this research under my instruction professor - Professor Chih-Ya Shen And huge thanks to my colleagues \u7f85\u58eb\u921e and \u9ec3\u7ae3\u8a73","title":"Modeling user willingness of data contribution in online social networks"},{"location":"modeling_user_willingness/modeling_user_willingness/#modeling-user-willingness-of-data-contribution-in-online-social-networks","text":"","title":"Modeling user willingness of data contribution in online social networks"},{"location":"modeling_user_willingness/modeling_user_willingness/#help-to-collect-your-data-from-social-network-faster","text":"","title":"Help to collect your data from social network faster"},{"location":"modeling_user_willingness/modeling_user_willingness/#abstract","text":"As the social network becoming one of the most important parts in our daily life, the data we produce while interacting with the social networks became a valuable asset. Therefore, the protection over these data are escalating day by day. However, the research which requires to use the data from social networks can not be conducted smoothly. To gather the data, a lot of time was wasted. Therefore, my team and I implemented a Python Machine Learning model that helps to collect data from social network in a more efficient fashion by judging the willingness of the user group intelligently.","title":"Abstract"},{"location":"modeling_user_willingness/modeling_user_willingness/#problem-research","text":"Under the implementation of GDPR(General Data Protection Regulation) since 2018, Social network companies like Facebook and Twitter would apply more protection to their data. However, in order to research on topics regarding social networks, data collection would become harder. Hence, we would like to acquire the public data on social network and analyze them through machine learning model based on the individual elements and situational elements. Eventually, we would like to find users who are more likely to provide their private data through our model.","title":"Problem Research"},{"location":"modeling_user_willingness/modeling_user_willingness/#analyze-process","text":"","title":"Analyze Process"},{"location":"modeling_user_willingness/modeling_user_willingness/#questions","text":"What is the relationship between the user willingness and their public data? Generally there are ground truth for questions to be solved by ML models, however, is there such a ground truth in our question? The young people are more likely to receive our survey instead of the elder ones. Will this cause any bias problem? Lots of values on the public data would be missing, is it possible to solve the problem through preprocessing? How to select the model and refine it to increase accuracy and eventually reach the goal?","title":"Questions"},{"location":"modeling_user_willingness/modeling_user_willingness/#flowchart","text":"Flowchart of our model","title":"Flowchart"},{"location":"modeling_user_willingness/modeling_user_willingness/#current-research-comparioson","text":"Social network now plays an important role in everyone's life, therefore the protection of eyeryone's data becomes an important question. The following paragraph will focus solely on the relationship between user willingness and their behavior and data","title":"Current Research Comparioson"},{"location":"modeling_user_willingness/modeling_user_willingness/#user-consent-analysis","text":"The elements which affect social group willingness are as following: Privacy Paradox Users care about their privacy when asked about, but they don't protect their privacy enough on the Internet Perceived Privacy Users' perception of privacy danger differ from the actual danger Context Users' more likely to trade their private data for services or benefits Culture Different culture treats privacy differently User Diversity Users' education background, personality and etc. affect how they react to privacy protection Gender Different gender treats privacy with different attitude We would conduct our research according to the above aspects in a data science perspective","title":"User Consent Analysis"},{"location":"modeling_user_willingness/modeling_user_willingness/#implementation-process","text":"","title":"Implementation Process"},{"location":"modeling_user_willingness/modeling_user_willingness/#data-collection","text":"Collect the users' willingness through survey over Faceboook regarding: Whether they are willing to give their public account information to academic experiemnts without payment Whether they are willing to give their public account information to academic experiemnts with payment Whether they are willing to give their private account information to academic experiemnts without payment Whether they are willing to give their private account information to academic experiemnts with payment The survevry is distributed on multi different platform and channel to achieve as little bias as possible. Crawl the data according to users' willingness. Mostly their public account information such as personal data friend list liked posts number of posts We used selenium and Beautiful Soup and several bot afcebook accounts to crawl the above mentioned data The active data like posts and likes are crawled in a limited time frame","title":"Data collection"},{"location":"modeling_user_willingness/modeling_user_willingness/#data-preprocessing","text":"The dimension of the raw data is quite high - for over 37 different attributes including educational background, working experience, birthday and etc. The raw data also has a quite high percentage of missing values. If one attribute has too high missing value, it will be removed. If low missing value, interpolation is used to fill up the missing value For Example, User ID is removed because it does not provide any meaning The raw data is then categorized using nominal feature, ordinal feature and temporal feature. If features are being too similar, we would combine the features together For nominal features, one-hot encoding is applied to remove bias. For some of the ordinal features, total and frequency over time can be calculated. As for the temporal features, most of these are binned up by a week or a month We categorized users' hometown and living place according to continentals using GeoMapping and Google Maps API. We sorted the educational backgrounds according to the QS and similar ranking standards The raw data is then divided into train data and test data using K-fold cross validation The raw data is scaled standardized and normalized as well The feature selection and extraction were then applied to the raw data. Such as Sequential Backward Selection to remove noises and LDA can select important features.","title":"Data Preprocessing"},{"location":"modeling_user_willingness/modeling_user_willingness/#training","text":"We selected several models such as SVM, random forest, adaboost and xgboost which fits better with smaller dataset We applied SMOTE to do upsampling to balance the ratio of the positive and negative data We then use grid search to refine the parameter for the model","title":"Training"},{"location":"modeling_user_willingness/modeling_user_willingness/#performance-conclusion","text":"The basic accuracy is around 72% After refining, the accuracy is now at 82% The accuracy can be further improved if more user data can be collected. Also, as described above, the users' willingness is highly related to one's personality as well, so maybe inspect the content of the posts to identify the personality would be a good break.","title":"Performance Conclusion"},{"location":"modeling_user_willingness/modeling_user_willingness/#active-learning","text":"As our research move on to the next level, we found out that we lack of data Our research is 'small-dataset', 'low cost to achieve non-labelled data' and 'high cost to label each data'. Therefore, it is a perfect fit for Active Learning Our plan is to crawl large data on Facebook and ask the user about his or her willingness about giving the data, which can further used on training the model itself. Model of the Active Learning The action to pick up which users to ask is called query strategy The labeled data would then be feed to an AL Learner There are various query strategies the unlabelled data. Besides the default methods, we implemented our own query strategy These query strategies were combined and cross-validated through the grid-search The iteration can quickly convergent after 200 queries And the result of the different query strategies are as followed:","title":"Active Learning"},{"location":"modeling_user_willingness/modeling_user_willingness/#reference","text":"Laufer, R. S. and Wolfe, M., Privacy as a concept and a social issue: Amultidimensional developmental theory, 1977. Martina Ziefle, Julian Halbey and Sylvia Kowalewski, Users\u2019 Willingness to ShareData on the Internet: Perceived Benefits and Caveats, 2016. Jie Zhao, Chanjuan Zhu, Zhixiang Peng, Xin Xu and Yan Liu, User Willingnesstoward Knowledge Sharing in Social Networks, 2018. Catherine, M., Some antecedents and effects of trust in virtual communities, 2002. Burr Settles, Active Learning Literature Survey, 2010.","title":"Reference"},{"location":"modeling_user_willingness/modeling_user_willingness/#my-role-in-the-project","text":"I am mainly responsible for the data preprocessing and model refining I refined the model to increase its accuracy for 20% Furthermore, I handled most of the implementation of the Active Learning's query strategies","title":"My role in the project"},{"location":"modeling_user_willingness/modeling_user_willingness/#conclusion","text":"As my Bachelor's thesis, this Project brought me great impact over ML Its the very first big scale ML project I not only learned the programming of ML but also the proper way of conducting research on ML-related issues The project also increased my interests on the social computing I started to be aware of the things that we missed when using the convenient services provided by the online/game companies these days When they tricked us in exchange with our priceless data, they didn't protect them and ever worse. Some of them even sell them for benefits. I am proud that I have conducted this research under my instruction professor - Professor Chih-Ya Shen And huge thanks to my colleagues \u7f85\u58eb\u921e and \u9ec3\u7ae3\u8a73","title":"Conclusion"},{"location":"nsfw_detection/nsfw_detection/","text":"NSFW Detection Not Safe For Work content detection API Introduction The NSFW Detection is a RESTful API which can identify adult content through a CNN-model The NSFW Detection is built with Django The NSFW Detection is containerized into Dockerfile and docker-compose, so you can deploy them in any docker-installed instance Requirements of the project Batalk is an online board game platform It grew to a larger user population and the user regulation became stricter when the chat function is developed App Store requires Batalk to developed a mechanism to filter the NSFW(Not Safe For Work) content Therefore, the task is to developed an API which can detect whether the uploaded images to the server is NSFW or SFW(Safe For Work) Possible solutions While there are several popular backend frameworks which are suitable for the project, I still recommended Django as the Backend Framework Not only because I am familiar with this framework but also because it provides a very intuitive way to establish an admin backstage for the maintainer to inspect the status Concept of Implementation The NSFW Detection uses the Tensorflow Implementation of Yahoo's Open NSFW Model to act as the detector When NSFW Detection receives an API request, it would first be distributed through Nginx Then the uwsgi would receive the data from Nginx so Django may be able to process the info The Django engine would identify the input type, e.g. url, image or base64 and issue them to relative corresponding serializers Serializers would then preprocessing each image and use the detection model to detect the image Then the result which contains file_name, user_id, test_score and etc. would be returned The NSFW Detection also has an admin backstage which can be access through browser and monitor the status of the detection status The NSFW Detection can deal high-concurrency problems using Nginx The average response time is 3~4 seconds My role in the project This is the project during my intership in Batalk LTD. I am responsible for all of the implementation of the tasks The features and functions are requirements from my manager Leo Zhang Github Links https://github.com/tpchris1/nsfw_detection","title":"NSFW Detection"},{"location":"nsfw_detection/nsfw_detection/#nsfw-detection","text":"","title":"NSFW Detection"},{"location":"nsfw_detection/nsfw_detection/#not-safe-for-work-content-detection-api","text":"","title":"Not Safe For Work content detection API"},{"location":"nsfw_detection/nsfw_detection/#introduction","text":"The NSFW Detection is a RESTful API which can identify adult content through a CNN-model The NSFW Detection is built with Django The NSFW Detection is containerized into Dockerfile and docker-compose, so you can deploy them in any docker-installed instance","title":"Introduction"},{"location":"nsfw_detection/nsfw_detection/#requirements-of-the-project","text":"Batalk is an online board game platform It grew to a larger user population and the user regulation became stricter when the chat function is developed App Store requires Batalk to developed a mechanism to filter the NSFW(Not Safe For Work) content Therefore, the task is to developed an API which can detect whether the uploaded images to the server is NSFW or SFW(Safe For Work)","title":"Requirements of the project"},{"location":"nsfw_detection/nsfw_detection/#possible-solutions","text":"While there are several popular backend frameworks which are suitable for the project, I still recommended Django as the Backend Framework Not only because I am familiar with this framework but also because it provides a very intuitive way to establish an admin backstage for the maintainer to inspect the status","title":"Possible solutions"},{"location":"nsfw_detection/nsfw_detection/#concept-of-implementation","text":"The NSFW Detection uses the Tensorflow Implementation of Yahoo's Open NSFW Model to act as the detector When NSFW Detection receives an API request, it would first be distributed through Nginx Then the uwsgi would receive the data from Nginx so Django may be able to process the info The Django engine would identify the input type, e.g. url, image or base64 and issue them to relative corresponding serializers Serializers would then preprocessing each image and use the detection model to detect the image Then the result which contains file_name, user_id, test_score and etc. would be returned The NSFW Detection also has an admin backstage which can be access through browser and monitor the status of the detection status The NSFW Detection can deal high-concurrency problems using Nginx The average response time is 3~4 seconds","title":"Concept of Implementation"},{"location":"nsfw_detection/nsfw_detection/#my-role-in-the-project","text":"This is the project during my intership in Batalk LTD. I am responsible for all of the implementation of the tasks The features and functions are requirements from my manager Leo Zhang","title":"My role in the project"},{"location":"nsfw_detection/nsfw_detection/#github-links","text":"https://github.com/tpchris1/nsfw_detection","title":"Github Links"},{"location":"the_haunted_village/the_haunted_village/","text":"The Haunted Village Escape from the ghosts with you besties on PC! Introduction Problem Research Analyze Process Implementation Process My role in the project Conclusion","title":"The Haunted Village"},{"location":"the_haunted_village/the_haunted_village/#the-haunted-village","text":"","title":"The Haunted Village"},{"location":"the_haunted_village/the_haunted_village/#escape-from-the-ghosts-with-you-besties-on-pc","text":"","title":"Escape from the ghosts with you besties on PC!"},{"location":"the_haunted_village/the_haunted_village/#introduction","text":"","title":"Introduction"},{"location":"the_haunted_village/the_haunted_village/#problem-research","text":"","title":"Problem Research"},{"location":"the_haunted_village/the_haunted_village/#analyze-process","text":"","title":"Analyze Process"},{"location":"the_haunted_village/the_haunted_village/#implementation-process","text":"","title":"Implementation Process"},{"location":"the_haunted_village/the_haunted_village/#my-role-in-the-project","text":"","title":"My role in the project"},{"location":"the_haunted_village/the_haunted_village/#conclusion","text":"","title":"Conclusion"},{"location":"the_tank/the_tank_arduino/","text":"The Tank Gen2 - Arduino Based A STRONGER Lego Tank!! Introduction This is a Arduino-based mobile Lego tank which can be controlled by an Android phone through Blynk The Tank Gen2 is the upgrade version of the Gen1 - FPGA-based one Since the Gen1 is rather small and not strong enough Gen2 has made a significantly big change compared with Gen1 Be sure to check Gen1 if you want more details for the background stories Feature It has two main structural parts Upper: Turrent Turrent can lift and turn left and right Turrent can fire Lower: Base Base can also turn left and right There are a total of 4 motors to drive the Turrent and the Base It has two front lights which can be manually controlled through push buttons It has an Ultrasonic sensor that can detect enemy upfront It has a Thermal sensor which can light up alarm RGB LED to certain temperature and humdity It has a Photon Resistor which can light up the front lights when environment is dark It has a Canon which can shoot Lego parts and is controlled by a solenoid Moving, Shooting and Lighting can be controlled by an Android Phone through Blynk The Tank communicates with the phone by Bluetooth through a HC05 Bluetooth Chip Parts Used TO BE FILLED Please refer to Architecture first Architecture Demo Development Phase 1: Base Structure Development Phase 2: Phone Working Development Phase 3: Torrent Moving Development Phase 4: Shooting Development Phase 5: Moving My role in the project This is the final project of the course Intro. to Embedded System I am responsible for all of the implementation of the tasks including Lego mechanism, circuits and motors and programming over Arduino Conclusion I have learned the entire Arduino system through the project The structure is still imperfect. However, the process of making the project grants me the ability to integrate various system With the numerous failure during the project, I have also learned how to \"debug\" in a systematic way Huge thanks to the lecturer of the course Chung-Ta King and help from my roommate Kai-Chen Lin and Edward Wei Ding","title":"Gen2 - Arduino-based"},{"location":"the_tank/the_tank_arduino/#the-tank-gen2-arduino-based","text":"","title":"The Tank Gen2 - Arduino Based"},{"location":"the_tank/the_tank_arduino/#a-stronger-lego-tank","text":"","title":"A STRONGER Lego Tank!!"},{"location":"the_tank/the_tank_arduino/#introduction","text":"This is a Arduino-based mobile Lego tank which can be controlled by an Android phone through Blynk The Tank Gen2 is the upgrade version of the Gen1 - FPGA-based one Since the Gen1 is rather small and not strong enough Gen2 has made a significantly big change compared with Gen1 Be sure to check Gen1 if you want more details for the background stories","title":"Introduction"},{"location":"the_tank/the_tank_arduino/#feature","text":"It has two main structural parts Upper: Turrent Turrent can lift and turn left and right Turrent can fire Lower: Base Base can also turn left and right There are a total of 4 motors to drive the Turrent and the Base It has two front lights which can be manually controlled through push buttons It has an Ultrasonic sensor that can detect enemy upfront It has a Thermal sensor which can light up alarm RGB LED to certain temperature and humdity It has a Photon Resistor which can light up the front lights when environment is dark It has a Canon which can shoot Lego parts and is controlled by a solenoid Moving, Shooting and Lighting can be controlled by an Android Phone through Blynk The Tank communicates with the phone by Bluetooth through a HC05 Bluetooth Chip","title":"Feature"},{"location":"the_tank/the_tank_arduino/#parts-used","text":"TO BE FILLED Please refer to Architecture first","title":"Parts Used"},{"location":"the_tank/the_tank_arduino/#architecture","text":"","title":"Architecture"},{"location":"the_tank/the_tank_arduino/#demo","text":"Development Phase 1: Base Structure Development Phase 2: Phone Working Development Phase 3: Torrent Moving Development Phase 4: Shooting Development Phase 5: Moving","title":"Demo"},{"location":"the_tank/the_tank_arduino/#my-role-in-the-project","text":"This is the final project of the course Intro. to Embedded System I am responsible for all of the implementation of the tasks including Lego mechanism, circuits and motors and programming over Arduino","title":"My role in the project"},{"location":"the_tank/the_tank_arduino/#conclusion","text":"I have learned the entire Arduino system through the project The structure is still imperfect. However, the process of making the project grants me the ability to integrate various system With the numerous failure during the project, I have also learned how to \"debug\" in a systematic way Huge thanks to the lecturer of the course Chung-Ta King and help from my roommate Kai-Chen Lin and Edward Wei Ding","title":"Conclusion"},{"location":"the_tank/the_tank_fpga/","text":"The Tank Gen1 - FPGA Based A Lego Tank!! Introduction This is an FPGA-based mobile Lego tank which can be controlled through keyboard The FPGA is the Digilent Basys-3 Dev Kit developed under Vivado using Verilog The Tank is equipped with two 5V stepper motors powered by 4 AA 1.5V batteries The Tank is also equipped with another stepper motor to power the base of the canon which can fire Lego using solenoid Problem Research When my teammate and I decided to start this project, we had no clue of which components or parts we were going to use But we were very clear about what our goals are A Lego tank It can move It has a canon or turrent which can move It can fire Lego bricks It can be ccontrolled by some sort of controller Based on the above goals, we wanted to verify the feasibility of these goals First of all, we wanted to verify whether our FPGA board can drive a motor with load. After several discussion, we believe that the DC motor we could bought cannot provide enough torque. Hence, we chose stepper motors to drive the Tank Therefore, we tried to power the motors through a very simple experiment with some motors, some ULN2003 drive boards and some tissue, some wire and 4 AA batteries. It turned out to be pretty successful, then we can formally establish proposal of this project and go for next stage Feature The Tank can move forward and backward The Tank can move left and right The Tank can rotate the canon horizontally The Tank can make sounds when firing the canon The Tank can show the current status using 7-segment display The Tank can simulate an engine start and off using FSM The sketch design of the FSM for the Tank is as below Implementation Process The Lego structure is the very first important thing to finish because we needed to make sure that the structure was stongr enough to load these many parts on it Therefore, the base of the Tank is as below 3. Our ultimate goal for the Tank to be looking like this 4. Two stepper motors is placed vertically to reduce space problem and they were connected to Lego axis as the following picture The stepper motors drive the belt through straight bevel gear After the base structure, we tested the driving system of the motors. The motors are drive through ULN2003 to magnify the signal from 3.3V to 5V The signals were set as a shifting 4-bit register to represent the 4 phases of the stepper motor. 8. Nevertheless, the power is not strong enough to drive all three motors including the one rotating the platform for the canon 9. The solution was to use external power to solve the problem 10. While my partner worked on the keyboard control and functions like LED and 7-segments, I began to work on the fire mechanism. After several research, I decided to use solenoid to pull the \"trigger\" for the canon 11. The canon is built on a platform and another worm drive . The platform is driven by another stepper motor and the worm drive can be manually controlled 12. Eventually, all parts are combined together and the Tank is complete 13. During the final demo, because we lack of power we had to use different external power to power the Tank 14. Demo video: My role in the project I mainly handled the design of all Lego structures and the design of circuits and layouts I was also responsible for the Verilog code of the stepper motor Conclusion Huge thanks to the lecturer of the course Professor Chih-Tsun Huang Unlimited thanks to my best partner Edward Wei Ding for the great help and support As Wei Ding and I grew interests in the world of FPGA, we later on became the TA for this course.","title":"Gen1 - FPGA-based"},{"location":"the_tank/the_tank_fpga/#the-tank-gen1-fpga-based","text":"","title":"The Tank Gen1 - FPGA Based"},{"location":"the_tank/the_tank_fpga/#a-lego-tank","text":"","title":"A Lego Tank!!"},{"location":"the_tank/the_tank_fpga/#introduction","text":"This is an FPGA-based mobile Lego tank which can be controlled through keyboard The FPGA is the Digilent Basys-3 Dev Kit developed under Vivado using Verilog The Tank is equipped with two 5V stepper motors powered by 4 AA 1.5V batteries The Tank is also equipped with another stepper motor to power the base of the canon which can fire Lego using solenoid","title":"Introduction"},{"location":"the_tank/the_tank_fpga/#problem-research","text":"When my teammate and I decided to start this project, we had no clue of which components or parts we were going to use But we were very clear about what our goals are A Lego tank It can move It has a canon or turrent which can move It can fire Lego bricks It can be ccontrolled by some sort of controller Based on the above goals, we wanted to verify the feasibility of these goals First of all, we wanted to verify whether our FPGA board can drive a motor with load. After several discussion, we believe that the DC motor we could bought cannot provide enough torque. Hence, we chose stepper motors to drive the Tank Therefore, we tried to power the motors through a very simple experiment with some motors, some ULN2003 drive boards and some tissue, some wire and 4 AA batteries. It turned out to be pretty successful, then we can formally establish proposal of this project and go for next stage","title":"Problem Research"},{"location":"the_tank/the_tank_fpga/#feature","text":"The Tank can move forward and backward The Tank can move left and right The Tank can rotate the canon horizontally The Tank can make sounds when firing the canon The Tank can show the current status using 7-segment display The Tank can simulate an engine start and off using FSM The sketch design of the FSM for the Tank is as below","title":"Feature"},{"location":"the_tank/the_tank_fpga/#implementation-process","text":"The Lego structure is the very first important thing to finish because we needed to make sure that the structure was stongr enough to load these many parts on it Therefore, the base of the Tank is as below 3. Our ultimate goal for the Tank to be looking like this 4. Two stepper motors is placed vertically to reduce space problem and they were connected to Lego axis as the following picture The stepper motors drive the belt through straight bevel gear After the base structure, we tested the driving system of the motors. The motors are drive through ULN2003 to magnify the signal from 3.3V to 5V The signals were set as a shifting 4-bit register to represent the 4 phases of the stepper motor. 8. Nevertheless, the power is not strong enough to drive all three motors including the one rotating the platform for the canon 9. The solution was to use external power to solve the problem 10. While my partner worked on the keyboard control and functions like LED and 7-segments, I began to work on the fire mechanism. After several research, I decided to use solenoid to pull the \"trigger\" for the canon 11. The canon is built on a platform and another worm drive . The platform is driven by another stepper motor and the worm drive can be manually controlled 12. Eventually, all parts are combined together and the Tank is complete 13. During the final demo, because we lack of power we had to use different external power to power the Tank 14. Demo video:","title":"Implementation Process"},{"location":"the_tank/the_tank_fpga/#my-role-in-the-project","text":"I mainly handled the design of all Lego structures and the design of circuits and layouts I was also responsible for the Verilog code of the stepper motor","title":"My role in the project"},{"location":"the_tank/the_tank_fpga/#conclusion","text":"Huge thanks to the lecturer of the course Professor Chih-Tsun Huang Unlimited thanks to my best partner Edward Wei Ding for the great help and support As Wei Ding and I grew interests in the world of FPGA, we later on became the TA for this course.","title":"Conclusion"}]}